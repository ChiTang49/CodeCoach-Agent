"""
SPLADE ç´¢å¼•å•ç‹¬æ„å»ºè„šæœ¬
å¤ç”¨å·²æœ‰çš„ BM25 chunk æ•°æ®ï¼ˆrag_data/bm25_chunks.jsonï¼‰ï¼Œ
æ— éœ€é‡æ–°è§£æ PDF æˆ–é‡å»º Qdrant/BM25 ç´¢å¼•ã€‚

ç”¨æ³•ï¼š
    conda activate agent
    python build_splade_index.py
"""
import os
import sys
import json
import time
from dotenv import load_dotenv

load_dotenv()

from rag.models import KnowledgeChunk
from rag.retrievers.splade import SpladeRetriever


def main():
    chunks_path = os.path.join(os.path.dirname(__file__), "rag_data", "bm25_chunks.json")

    if not os.path.exists(chunks_path):
        print(f"âŒ æœªæ‰¾åˆ° chunk æ•°æ®: {chunks_path}")
        print("   è¯·å…ˆè¿è¡Œ rag_ingest.py å®Œæˆ PDF è§£æå’ŒåŸºç¡€ç´¢å¼•æ„å»º")
        sys.exit(1)

    # åŠ è½½å·²æœ‰ chunk æ•°æ®
    print("ğŸ“‚ åŠ è½½å·²æœ‰ chunk æ•°æ®...")
    with open(chunks_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    chunks = []
    for item in data:
        chunks.append(KnowledgeChunk(
            chunk_id=item["chunk_id"],
            content=item["content"],
            source=item["source"],
            chapter=item.get("chapter", ""),
            section=item.get("section", ""),
            keywords=item.get("keywords", []),
        ))

    print(f"   å…± {len(chunks)} ä¸ª chunk")
    print()

    # æ„å»º SPLADE ç´¢å¼•
    print("ğŸ§ª æ„å»º SPLADE ç´¢å¼•...")
    print("   é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½ SPLADE æ¨¡å‹ï¼ˆ~500MBï¼‰ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    start = time.time()

    splade = SpladeRetriever()
    splade.build_index(chunks)

    elapsed = time.time() - start
    print(f"   è€—æ—¶: {elapsed:.1f}s")
    print()

    # éªŒè¯
    print("âœ… éªŒè¯ SPLADE æ£€ç´¢...")
    test_results = splade.retrieve("åŠ¨æ€è§„åˆ’çŠ¶æ€è½¬ç§»", top_k=3)
    print(f"   æµ‹è¯•æ£€ç´¢ 'åŠ¨æ€è§„åˆ’çŠ¶æ€è½¬ç§»': æ‰¾åˆ° {len(test_results)} ä¸ªç»“æœ")
    for i, rc in enumerate(test_results):
        print(f"   {i+1}. [{rc.chunk.chapter}] {rc.chunk.section} (score={rc.score:.4f})")

    print()
    print("ğŸ‰ SPLADE ç´¢å¼•æ„å»ºå®Œæˆï¼")


if __name__ == "__main__":
    main()
